{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import dotenv_values\n",
    "from spacy import displacy\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hp_nlp_graph.scraper import Chapter, Character\n",
    "from hp_nlp_graph.coreference import (\n",
    "    coref_resolve_and_get_characters_matches_in_chapter,\n",
    "    get_interactions,\n",
    ")\n",
    "from hp_nlp_graph.language import (\n",
    "    get_coref_resolver_nlp,\n",
    "    add_entity_ruler,\n",
    "    get_matcher,\n",
    "    FastCoref,\n",
    ")\n",
    "from hp_nlp_graph.utils import get_characters_seen_till_chapter\n",
    "from hp_nlp_graph.language_constants import CHAPTER_HARDCODED_OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_number = 7\n",
    "book_text_path = \"./data/books/7 Deathly Hallows.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_characters = {}\n",
    "for book_number_ in range(1, 8):\n",
    "    chapter_characters[book_number_] = pickle.load(\n",
    "        open(f\"data/processed/{book_number_}/chapter_characters.pkl\", \"rb\")\n",
    "    )\n",
    "characters = [\n",
    "    character\n",
    "    for book_number_, chapters in chapter_characters.items()\n",
    "    for chapter in chapters\n",
    "    for character in chapter.characters\n",
    "]\n",
    "chapter_characters = {\n",
    "    book_number_: {chapter.chapter: chapter.characters for chapter in chapters}\n",
    "    for book_number_, chapters in chapter_characters.items()\n",
    "}\n",
    "chapters = open(book_text_path, \"r\").read().split(\"CHAPTER \")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:08 - INFO - \t missing_keys: []\n",
      "11/01/2023 14:52:08 - INFO - \t unexpected_keys: []\n",
      "11/01/2023 14:52:08 - INFO - \t mismatched_keys: []\n",
      "11/01/2023 14:52:08 - INFO - \t error_msgs: []\n",
      "11/01/2023 14:52:08 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n"
     ]
    }
   ],
   "source": [
    "base_nlp, nlp = get_coref_resolver_nlp(device=\"cuda:0\")\n",
    "base_nlp = add_entity_ruler(base_nlp, characters)\n",
    "nlp = add_entity_ruler(nlp, characters)\n",
    "coref = FastCoref(base_nlp, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hp_nlp_graph.language import REMOVE_WORDS\n",
    "\n",
    "# matcher = get_matcher(base_nlp, get_character_dict(chapter_characters, 7, 37))\n",
    "# s = \"Hogwarts house-elves\"\n",
    "# print(matcher.has_key(s), matcher.get(s))\n",
    "# print(set(s.split(\" \")).isdisjoint(set(REMOVE_WORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dark Lord Ascending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d87eff8de1440eba1a2e7dfce152b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea6c1d01c3a46e5af1b3b097de8e8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:12 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Memoriam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d0aa7bf6084355b4dfb9fcfd5964e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9392565845a84fcd8c718dc3f47cd66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d128d3aab84429a26acc12d5d4701d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:17 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dursleys Departing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c63c79bc4344b993204ae286d8707d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff6606b115f4783bde497ecdd1c48d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48c1f9eae5a4c708e747e8e6ae4f23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:21 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Seven Potters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5676180bb4445787db3b98a1dae9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15653d9dc44480692f3ac8821f2efb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc23f6b7c304bd68fc32c955783ef6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304c3644f6e04b48b83cbe058f28b805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:26 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallen Warrior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aaf72cb523422abb0506887d9564b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7d92f5fe2642809a1f6e809f105748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016cb3eee9544073bcdce6ccc166eeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901bcf7ef52e4ef2998436af663710f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:32 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ghoul in Pajamas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da0c521fc2746b08541377711164a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe5b14f26a744e082de63ce8a1b9ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2264c12ca14ca0bf1d9cafe9288af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9725d337d2d74187845cab00b7220c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e583f445160422fa54373ab6a800649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:40 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Will of Albus Dumbledore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2c887d690f4b25a50acd59aad13239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bc136f85014a3c93a8e233678f37a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b044dccde1d94ff09b6ed72f06d84d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ca4b087af4304b533bc94cedf2d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2821eef7c24f75bf8574388b38e7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:47 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccd72146f0a4be89683f5eaf12120c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b749edcad493424380368533faba32fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb286b423b648579286043cee6a54ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4182c18353be4a6a8078c17610e10eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:53 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Place to Hide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2709388120f44ee95ea3ef25040b082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2868a4aa794e4d9888eb33b0138605d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:57 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:52:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365b6863be64f18924dac9996243ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:52:58 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kreacher’s Tale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77431780e6545ba8ee5259d53291c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc8e76453cf43ea81144baa219c87cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10fe285bee848c3b64db6dd3553b7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf87e5959f34a0e8e53f6763713006b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:04 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bribe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237e2363078b48e7a2eab01fb7872d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b1baab958d4be3b2d31c7eb4faaafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187bb14042f44c87b842b33973ff2e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c86ac409eb46e0be87a79617e16959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:11 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic is Might\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb0039925649c2ab88788a0623acbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7474d16950a646a1bb81b87adff32ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e640327a04c3b923c7f749b2fdb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff25d0ab77c470289cac0f28c68e18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:17 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Muggle-Born Registration Commission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8600586bdb144c6803e558797ab4484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c21c965dda4d7fb91e1317a34aab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47014d39310b4d6a8caaacac6bf15060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355bd4d1a4004a349de57b8d504a5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:23 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Thief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daee0264faeb425b8e9acd5396fd6bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa5a3d26ec448599eb945c9a347be68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13c087fabf347f58fff47b802bb6a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Goblin’s Revenge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1936d7b46e412d9e126fb2199b0fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f1bd0f89db489ab88389fcb93d7e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d28a3e1265c4e3491d730f4ee37c051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817c3b5fe604347b0d7f36fcd834c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73204e099f7745e6b0414b945dce219b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:35 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Godric’s Hollow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6599153822ed4f3ab713a3dae9773911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0843c609b04bef9bebc606cdafd840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6778186c0cca4e02ac619c25a147de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0f750e3bb4beeb17fbcf1e39461ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:40 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bathilda’s Secret\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0078e7693dd144099a5ba544279528a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb353ad93e74b769af597538dfb4af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57468bbf5364e2a9d61c5c796e33aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4c4b20950d462c982ce38096ea3c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Life and Lies of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bb58d54b584ddeb1884e24859a61d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4f99a29e2d4669b1c6e71078c6bd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4bb2ccbaa543bfb34badc1ef796148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:50 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Silver Doe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d219605ad0e474fa0a92cd2fc6b6d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dafc81e6a54a6298572da725f7898e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50412d034ca475499c0cda20fcc1942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c12ae093844061b09eb5a19b88338e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4ce3ce4bdc496ba5f8264e17a3308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xenophilius Lovegood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2fb6a2e1ba4383ba739ae23dc18e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:53:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a2e850c3cf445ab7fc91aabaeba2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:53:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e3e6fd13ec45509373f9c6bba74399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:00 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tale of The Three Brothers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553aa935d4384938870bfb02d5fc0b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbf50c5d4aa454e84d0a57b1a797086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:04 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c80bda537454091ce202840db6c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:05 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Deathly Hallows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81153141d57840149d13dce3d54bc01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c473323a2d4e01bff5a54f1fe72359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109f3fe8150c48d1be43940e7e3bccd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e47421a20e469db6fc457487b5627c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:12 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malfoy Manor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5b48c77a0b4dacaa9223e2cf2cb75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c072f08b0f4aa4bcf6c9d0ccfddfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced1082ebd3743928f2b9e713aa49639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1584074ed09f4b609fd3a6c7805a8e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d028029f504587b9a59236c6aeb4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:20 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wandmaker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c31ad0d2f1f48de96f50768b4a2ca4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd44c47fd864c65a6c2e3273bc63553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c874f77ea96841a0bd41fa04afd18ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6410d9980f824c41897dd7d7cc7171c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6f6d11828f4a0cac4647a2d3a4ab8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Cottage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54e642f2f1e44aca7347098a4898ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5cef28967c40a69c3426acbb4aff9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4f8b4d45024d6685a7d8a41dd8c088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:32 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gringotts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26ccc403ae04ed8a5f755ef3be4ce9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe66a144f94d48f2a37dd8e0e285b0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ad23966354384b6299f8f6bdfcce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1804a3e9b544b19be631238630a2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:38 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Final Hiding Place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4095e2ecdf24550b0a845a88120c5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4644c1b656c34ed9bb3b122b1d4a84ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:41 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Missing Mirror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f867ded068149a1bb64e5f43f2c1a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1538dfec7b3e431ab5cd259d3088bbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40250988938347acb70e1a868042ce26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lost Diadem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c753b1078c7d4364b616d712aa779163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e446f9e35a49b5b2ffdab5414721a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b048ce89f44b2eb9ab8cddda4e6b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:50 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sacking of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335d20e43cc94339b75385a778256549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d15cf3b98e4b6e926e0e0e94f61a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f50ac2f830a430f8cad9a57ea344f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d868e825b53144ef85d3fcd60e27e238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Battle Of Hogwarts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fa1b35088345ae967f16eed1213461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:54:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:54:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbeda9f2d3e4e08a23e7a0338674710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4097d24ce384ee2a3490473396dbe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fab99d293e4fe6a7ca73f6158a8d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15294f1aa3164bce87507d8b1250d35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:04 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Elder Wand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edf6391b8e84791b5dd1e36331a46e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0895bb99a3c747ae9f16b906ce5ad2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9614a127b1845d9913c4ef2ad2bbe11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d916a016a8f2482ea9ff3d4b4937b403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:10 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prince’s Tale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199be0a85ed54fe3805a16b452e12811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef3a8c8d9984ed48b2c1860ff26ebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d581569516147e98de534b7d4ebcc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fd8e9588d1414eb5fc2d340bed5125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a6b27ded3e4f9b868ba686e35e3cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b74974d46fb498ba3efc889d6da761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:18 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Forest Again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29371cc72c054fa6884b7c79176a37e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b2db6e49f43089864820d67ba9cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877637fd705a48edb8e11903d6f103cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:23 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King’s Cross\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4e2de53d874ab3adaa14f0bd036d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de0145b22574c4ca3d9a1ae7d498932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5515466e9b34cd5b71984a066d33335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06293701c18a475aa9284d22b10da82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:28 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Flaw in the Plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccf6c3ec8b747819bcce0630c51e7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357569bfc9447bf8b4cbd69fd17f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a0d8c4a7e74f21ab83ae70aa89e158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662b79c0bd5941bf91ad1e1607ade9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1932bf6749404e369c56d02dde95d16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:35 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epilogue: Nineteen Years Later\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2b1c7077d54ffb910a8de826803a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "11/01/2023 14:55:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64631d26c404b9ca28cb1aa8e2accdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/01/2023 14:55:37 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    }
   ],
   "source": [
    "interactions_by_chapter = {}\n",
    "# with open(f\"data/processed/{book_number}/interactions_by_chapter.pkl\", \"rb\") as f:\n",
    "#     interactions_by_chapter = pickle.load(f)\n",
    "for chapter in range(1, len(chapters) + 1):\n",
    "    # for chapter in range(37, len(chapters) + 1):\n",
    "    result, resolved_doc = coref_resolve_and_get_characters_matches_in_chapter(\n",
    "        base_nlp=base_nlp,\n",
    "        nlp=nlp,\n",
    "        chapter_text=chapters[chapter - 1],\n",
    "        characters_seen_till_this_chapter=get_characters_seen_till_chapter(\n",
    "            chapter_characters, book_number, chapter\n",
    "        ),\n",
    "        coref_resolver=coref.resolve,\n",
    "        chapter_hardcoded_options=CHAPTER_HARDCODED_OPTIONS[f\"{book_number}-{chapter}\"]\n",
    "        if f\"{book_number}-{chapter}\" in CHAPTER_HARDCODED_OPTIONS\n",
    "        else None,\n",
    "    )\n",
    "    interactions_by_chapter[chapter] = dict(get_interactions(result, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/processed/{book_number}/interactions_by_chapter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(interactions_by_chapter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
